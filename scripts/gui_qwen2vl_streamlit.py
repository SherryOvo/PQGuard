#!/usr/bin/env python3
"""
Qwen2-VL å¤šæ¨¡æ€æ¨¡å‹ GUI ç•Œé¢ï¼ˆä½¿ç”¨ Streamlitï¼‰

åŠŸèƒ½ï¼š
- æ–‡æœ¬å¯¹è¯
- å›¾åƒè¯†åˆ«å’Œé—®ç­”
- è¯­éŸ³è¾“å…¥ï¼ˆä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼‰
- è°ƒç”¨è®­ç»ƒå¥½çš„æ¨¡å‹

ä½¿ç”¨ Streamlit æ„å»º Web ç•Œé¢ï¼ˆæ›´ç®€å•ç¨³å®šï¼‰
"""

import sys
import os
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
import tempfile
import warnings

# è®¾ç½®æ¨¡å‹ç¯å¢ƒå˜é‡ï¼ˆåœ¨å¯¼å…¥ transformers ä¹‹å‰ï¼‰
sys.path.insert(0, str(Path(__file__).parent))
import env_model

import torch
from transformers import AutoProcessor, AutoModelForVision2Seq
from PIL import Image
import streamlit as st

# è¯­éŸ³ç›¸å…³
try:
    import whisper
    import soundfile as sf
    import librosa
    import numpy as np
    SPEECH_AVAILABLE = True
except ImportError:
    SPEECH_AVAILABLE = False
    whisper = None
    sf = None
    librosa = None

# è‡ªåŠ¨æŸ¥æ‰¾è®­ç»ƒå¥½çš„æ¨¡å‹
_MODEL_DIR = Path("outputs/qwen2vl_beer_sft")
_BASE_MODEL_ID = "Qwen/Qwen2-VL-7B-Instruct"

if _MODEL_DIR.exists() and (_MODEL_DIR / "config.json").exists():
    MODEL_ID = str(_MODEL_DIR)
else:
    MODEL_ID = _BASE_MODEL_ID


@st.cache_resource
def load_model():
    """åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨ï¼ˆä½¿ç”¨ Streamlit ç¼“å­˜ï¼‰ã€‚"""
    print(f"åŠ è½½æ¨¡å‹: {MODEL_ID}...")
    
    processor = AutoProcessor.from_pretrained(
        MODEL_ID,
        trust_remote_code=True,
    )
    
    model = AutoModelForVision2Seq.from_pretrained(
        MODEL_ID,
        trust_remote_code=True,
        torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,
        device_map="auto" if torch.cuda.is_available() else {"": "cpu"},
    )
    model.eval()
    
    return processor, model


@st.cache_resource
def load_whisper_model():
    """åŠ è½½ Whisper æ¨¡å‹ï¼ˆä½¿ç”¨ Streamlit ç¼“å­˜ï¼‰ã€‚
    ä½¿ç”¨ 'small' æ¨¡å‹ä»¥è·å¾—æ›´å¥½çš„è¯†åˆ«å‡†ç¡®ç‡ï¼ˆæ¯” 'base' æ›´å‡†ç¡®ï¼Œæ¯” 'medium' æ›´å¿«ï¼‰ã€‚
    """
    if not SPEECH_AVAILABLE:
        return None
    try:
        # å°è¯•åŠ è½½ 'small' æ¨¡å‹ï¼ˆå‡†ç¡®ç‡æ›´é«˜ï¼‰
        # å¦‚æœæ˜¾å­˜ä¸è¶³ï¼Œå¯ä»¥å›é€€åˆ° 'base'
        try:
            return whisper.load_model("small")
        except Exception as e1:
            print(f"åŠ è½½ Whisper small æ¨¡å‹å¤±è´¥: {e1}ï¼Œå°è¯• base æ¨¡å‹...")
            return whisper.load_model("base")
    except Exception as e:
        print(f"åŠ è½½ Whisper æ¨¡å‹å¤±è´¥: {e}")
        return None


def resize_image(image: Image.Image, max_size: int = 512) -> Image.Image:
    """è°ƒæ•´å›¾åƒå¤§å°ä»¥èŠ‚çœæ˜¾å­˜ï¼ˆå¤šæ¨¡æ€æ¨¡å‹å›¾åƒå¤„ç†æ˜¾å­˜å ç”¨å¤§ï¼‰ã€‚"""
    width, height = image.size
    if width <= max_size and height <= max_size:
        return image
    
    # ä¿æŒå®½é«˜æ¯”ç¼©æ”¾ï¼ˆé™åˆ¶æœ€å¤§è¾¹é•¿ä¸º512åƒç´ ï¼‰
    if width > height:
        new_width = max_size
        new_height = int(height * max_size / width)
    else:
        new_height = max_size
        new_width = int(width * max_size / height)
    
    return image.resize((new_width, new_height), Image.Resampling.LANCZOS)


def _convert_chat_history(chat_history: List[Tuple[str, str]]) -> List[Dict[str, str]]:
    """å°† Streamlit å¯¹è¯å†å²æ ¼å¼è½¬æ¢ä¸ºæ¨¡å‹éœ€è¦çš„æ ¼å¼ã€‚
    
    Args:
        chat_history: List of (role, content) tuples, e.g., [("user", "é—®é¢˜"), ("assistant", "å›ç­”")]
    
    Returns:
        List of message dicts, e.g., [{"role": "user", "content": "é—®é¢˜"}, {"role": "assistant", "content": "å›ç­”"}]
    """
    messages = []
    for role, content in chat_history:
        messages.append({"role": role, "content": content})
    return messages


def generate_reply(text: str, image: Optional[Image.Image] = None, max_new_tokens: int = 128, chat_history: Optional[List[Tuple[str, str]]] = None) -> str:
    """ç”Ÿæˆå›å¤ï¼ˆæ”¯æŒå›¾åƒè¾“å…¥å’Œå¯¹è¯å†å²ï¼‰ã€‚
    
    Args:
        text: ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬
        image: å¯é€‰çš„å›¾åƒè¾“å…¥
        max_new_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
        chat_history: å¯¹è¯å†å²ï¼Œæ ¼å¼ä¸º List[Tuple[role, content]]
    """
    processor, model = load_model()
    
    # æ¸…ç©ºæ˜¾å­˜ç¼“å­˜
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    # å‡†å¤‡æ¶ˆæ¯ï¼ˆä½¿ç”¨å¯¹è¯å†å²æˆ–åˆ›å»ºæ–°å¯¹è¯ï¼‰
    system_prompt = "ä½ æ˜¯ä¸€åç²¾é€šç²¾é…¿å•¤é…’å·¥è‰ºã€è®¾å¤‡ç®¡ç†å’Œå¼‚å¸¸è¯Šæ–­çš„ä¸­æ–‡æ™ºèƒ½åŠ©æ‰‹ï¼Œæ”¯æŒå›¾åƒè¯†åˆ«å’Œè¯­éŸ³äº¤äº’ã€‚"
    
    if chat_history is not None and len(chat_history) > 0:
        # è½¬æ¢å¯¹è¯å†å²æ ¼å¼
        history_messages = _convert_chat_history(chat_history)
        # æ£€æŸ¥å†å²ä¸­æ˜¯å¦å·²ç»æœ‰ç³»ç»Ÿæç¤º
        has_system = any(msg.get("role") == "system" for msg in history_messages)
        # ä½¿ç”¨æä¾›çš„å¯¹è¯å†å²ï¼Œæ·»åŠ æ–°ç”¨æˆ·æ¶ˆæ¯
        if has_system:
            messages = history_messages + [{"role": "user", "content": text}]
        else:
            messages = [{"role": "system", "content": system_prompt}] + history_messages + [{"role": "user", "content": text}]
    else:
        # åˆ›å»ºæ–°å¯¹è¯
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": text},
        ]
    
    # å‡†å¤‡è¾“å…¥
    if image is not None:
        # è°ƒæ•´å›¾åƒå¤§å°ä»¥èŠ‚çœæ˜¾å­˜ï¼ˆé™åˆ¶æœ€å¤§å°ºå¯¸ä¸º512åƒç´ ï¼‰
        image = resize_image(image, max_size=512)
        
        # å¤šæ¨¡æ€è¾“å…¥ï¼ˆå›¾åƒ+æ–‡æœ¬ï¼‰
        messages_text = processor.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True,
        )
        inputs = processor(
            text=messages_text,
            images=[image],
            return_tensors="pt",
        )
    else:
        # çº¯æ–‡æœ¬è¾“å…¥
        messages_text = processor.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True,
        )
        inputs = processor(
            text=messages_text,
            return_tensors="pt",
        )
    
    # ç§»åŠ¨åˆ°æ¨¡å‹è®¾å¤‡
    inputs = {k: v.to(model.device) if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}
    
    # ç”Ÿæˆï¼ˆä¼˜åŒ–å‚æ•°ä»¥èŠ‚çœæ˜¾å­˜ï¼‰
    with torch.no_grad():
        # ä½¿ç”¨ torch.cuda.amp.autocast è¿›ä¸€æ­¥ä¼˜åŒ–æ˜¾å­˜
        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):
            generated_ids = model.generate(
                **inputs,
                max_new_tokens=max_new_tokens,  # é™åˆ¶æœ€å¤§ç”Ÿæˆé•¿åº¦
                temperature=0.7,
                top_p=0.8,
                do_sample=True,
                pad_token_id=processor.tokenizer.eos_token_id,
            )
    
    # æ¸…ç©ºæ˜¾å­˜ç¼“å­˜
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    # è§£ç 
    generated_ids_trimmed = [
        out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs["input_ids"], generated_ids)
    ]
    response = processor.batch_decode(
        generated_ids_trimmed,
        skip_special_tokens=True,
        clean_up_tokenization_spaces=False,
    )[0]
    
    return response


def _whisper_transcribe(whisper_model, audio_input, language="zh"):
    """ç»Ÿä¸€çš„ Whisper è½¬å½•å‡½æ•°ï¼Œä½¿ç”¨ä¼˜åŒ–çš„å‚æ•°æé«˜å‡†ç¡®ç‡ã€‚"""
    return whisper_model.transcribe(
        audio_input,
        language=language,
        fp16=False,
        verbose=False,
        beam_size=5,  # ä½¿ç”¨ beam search æé«˜å‡†ç¡®ç‡
        best_of=5,    # ç”Ÿæˆå¤šä¸ªå€™é€‰ç»“æœï¼Œé€‰æ‹©æœ€å¥½çš„
        temperature=0.0,  # ä½¿ç”¨è´ªå¿ƒè§£ç ï¼ˆç¡®å®šæ€§æ›´é«˜ï¼‰
        condition_on_previous_text=False,  # ä¸ä¾èµ–ä¹‹å‰çš„æ–‡æœ¬ï¼Œé¿å…é”™è¯¯ç´¯ç§¯
    )


def transcribe_audio(audio_path: str) -> str:
    """å°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡æœ¬ï¼ˆæ”¯æŒå¤šç§éŸ³é¢‘æ ¼å¼ï¼ŒåŒ…æ‹¬ .m4aï¼‰ã€‚"""
    if not SPEECH_AVAILABLE:
        return "è¯­éŸ³è¯†åˆ«åŠŸèƒ½æœªå®‰è£…ï¼Œè¯·å®‰è£…ï¼špip install openai-whisper soundfile librosa"
    
    if not os.path.exists(audio_path):
        return f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}"
    
    # åŠ è½½ Whisper æ¨¡å‹ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
    whisper_model = load_whisper_model()
    if whisper_model is None:
        return "æ— æ³•åŠ è½½ Whisper æ¨¡å‹ï¼Œè¯·æ£€æŸ¥å®‰è£…"
    
    file_ext = Path(audio_path).suffix.lower()
    temp_wav_path = None
    
    try:
        # ç­–ç•¥1ï¼šä¼˜å…ˆç›´æ¥ä½¿ç”¨ Whisper å¤„ç†ï¼ˆWhisper å†…ç½®äº† ffmpeg æ”¯æŒï¼Œå¯ä»¥ç›´æ¥å¤„ç†å¤šç§æ ¼å¼ï¼‰
        # è¿™å¯¹äº .m4aã€.mp3 ç­‰æ ¼å¼ç‰¹åˆ«æœ‰æ•ˆ
        try:
            result = _whisper_transcribe(whisper_model, audio_path, language="zh")
            text = result["text"].strip()
            if text:
                return text
            # å¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°æ–‡æœ¬ï¼Œç»§ç»­å°è¯•å…¶ä»–æ–¹æ³•
            print("Whisper ç›´æ¥å¤„ç†æœªè¯†åˆ«åˆ°æ–‡æœ¬ï¼Œå°è¯•å…¶ä»–æ–¹æ³•...")
        except Exception as e:
            error_msg = str(e).lower()
            # å¦‚æœé”™è¯¯ä¸ ffmpeg ç›¸å…³ï¼Œè®°å½•å¹¶ç»§ç»­å°è¯•å…¶ä»–æ–¹æ³•
            if "ffmpeg" in error_msg or "no such file" in error_msg:
                print(f"Whisper ç›´æ¥å¤„ç†å¤±è´¥ï¼ˆå¯èƒ½ç¼ºå°‘ ffmpegï¼‰: {e}ï¼Œå°è¯•è½¬æ¢...")
            else:
                print(f"Whisper ç›´æ¥å¤„ç†å¤±è´¥: {e}ï¼Œå°è¯•è½¬æ¢...")
        
        # ç­–ç•¥2ï¼šä½¿ç”¨ librosa åŠ è½½éŸ³é¢‘ï¼Œç„¶åè½¬æ¢ï¼ˆé€‚ç”¨äº librosa å¯ä»¥å¤„ç†çš„æ ¼å¼ï¼‰
        audio_array = None
        sample_rate = 16000
        
        try:
            # æŠ‘åˆ¶è­¦å‘Š
            with warnings.catch_warnings():
                warnings.filterwarnings("ignore", category=FutureWarning)
                warnings.filterwarnings("ignore", category=UserWarning)
                # ä½¿ç”¨ librosa åŠ è½½ï¼Œæ”¯æŒå¤šç§æ ¼å¼
                # å¯¹äº .m4a æ–‡ä»¶ï¼Œå¦‚æœç³»ç»Ÿæœ‰ ffmpegï¼Œlibrosa åº”è¯¥èƒ½å¤ŸåŠ è½½
                audio_array, sample_rate = librosa.load(
                    audio_path,
                    sr=16000,  # ç›´æ¥é‡é‡‡æ ·åˆ° 16kHz
                    mono=True,  # è½¬æ¢ä¸ºå•å£°é“
                    res_type='kaiser_best'  # é«˜è´¨é‡é‡é‡‡æ ·
                )
        except Exception as e:
            error_msg = str(e)
            # å¦‚æœ librosa ä¹Ÿå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ ffmpeg å‘½ä»¤è¡Œå·¥å…·è½¬æ¢
            print(f"librosa åŠ è½½å¤±è´¥: {error_msg}ï¼Œå°è¯•ä½¿ç”¨ ffmpeg è½¬æ¢...")
            
            # ç­–ç•¥3ï¼šä½¿ç”¨ ffmpeg å‘½ä»¤è¡Œå·¥å…·è½¬æ¢ä¸º WAVï¼ˆæœ€å¯é çš„æ–¹æ³•ï¼‰
            import subprocess
            
            # é¦–å…ˆæ£€æŸ¥ ffmpeg æ˜¯å¦å¯ç”¨ä¸”èƒ½æ­£å¸¸è¿è¡Œ
            ffmpeg_available = False
            try:
                # æ£€æŸ¥ ffmpeg æ˜¯å¦åœ¨ PATH ä¸­
                which_result = subprocess.run(['which', 'ffmpeg'], capture_output=True, text=True, timeout=5)
                if which_result.returncode == 0:
                    # å°è¯•è¿è¡Œ ffmpeg -version æ£€æŸ¥æ˜¯å¦èƒ½æ­£å¸¸å·¥ä½œ
                    version_result = subprocess.run(
                        ['ffmpeg', '-version'],
                        capture_output=True,
                        text=True,
                        timeout=5
                    )
                    if version_result.returncode == 0:
                        ffmpeg_available = True
                    else:
                        # ffmpeg å­˜åœ¨ä½†æ— æ³•è¿è¡Œï¼Œå¯èƒ½æ˜¯åº“ä¾èµ–é—®é¢˜
                        error_output = version_result.stderr if version_result.stderr else version_result.stdout
                        if "cannot open shared object file" in error_output or "shared libraries" in error_output:
                            print(f"è­¦å‘Šï¼šffmpeg å­˜åœ¨ä½†ç¼ºå°‘ç³»ç»Ÿåº“ä¾èµ–: {error_output[:200]}")
                            print("å»ºè®®ï¼šå¦‚æœé‡åˆ°åº“ç¼ºå¤±é—®é¢˜ï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤ä¿®å¤ï¼š")
                            print("  sudo ln -s /usr/lib/x86_64-linux-gnu/blas/libblas.so.3 /usr/lib/x86_64-linux-gnu/libblas.so.3")
                            print("  sudo ln -s /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3 /usr/lib/x86_64-linux-gnu/liblapack.so.3")
                            print("  sudo ldconfig")
                        ffmpeg_available = False
            except (subprocess.TimeoutExpired, FileNotFoundError, Exception) as e:
                print(f"ffmpeg æ£€æŸ¥å¤±è´¥: {e}")
                ffmpeg_available = False
            
            # å¦‚æœ ffmpeg å¯ç”¨ï¼Œå°è¯•ä½¿ç”¨å®ƒè½¬æ¢
            if ffmpeg_available:
                try:
                    # åˆ›å»ºä¸´æ—¶ WAV æ–‡ä»¶
                    temp_wav = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
                    temp_wav_path = temp_wav.name
                    temp_wav.close()
                    
                    # ä½¿ç”¨ ffmpeg è½¬æ¢ä¸º WAV
                    cmd = [
                        'ffmpeg',
                        '-i', audio_path,  # è¾“å…¥æ–‡ä»¶
                        '-ar', '16000',    # é‡‡æ ·ç‡ 16kHz
                        '-ac', '1',        # å•å£°é“
                        '-y',              # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                        '-loglevel', 'error',  # åªæ˜¾ç¤ºé”™è¯¯
                        temp_wav_path      # è¾“å‡ºæ–‡ä»¶
                    ]
                    
                    # è¿è¡Œè½¬æ¢å‘½ä»¤
                    result = subprocess.run(
                        cmd,
                        capture_output=True,
                        text=True,
                        timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
                    )
                    
                    if result.returncode == 0 and os.path.exists(temp_wav_path):
                        # è½¬æ¢æˆåŠŸï¼Œä½¿ç”¨è½¬æ¢åçš„ WAV æ–‡ä»¶
                        audio_path = temp_wav_path
                        file_ext = '.wav'
                        
                        # å°è¯•ä½¿ç”¨ Whisper ç›´æ¥å¤„ç†è½¬æ¢åçš„æ–‡ä»¶ï¼ˆæœ€å¿«ï¼‰
                        try:
                            result = _whisper_transcribe(whisper_model, audio_path, language="zh")
                            text = result["text"].strip()
                            if text:
                                return text
                        except Exception:
                            pass
                        
                        # å¦‚æœ Whisper ç›´æ¥å¤„ç†å¤±è´¥ï¼Œå°è¯•ç”¨ librosa åŠ è½½
                        try:
                            audio_array, sample_rate = librosa.load(
                                audio_path,
                                sr=16000,
                                mono=True,
                                res_type='kaiser_best'
                            )
                        except Exception as e2:
                            return f"è½¬æ¢åçš„éŸ³é¢‘æ— æ³•åŠ è½½: {str(e2)}"
                    else:
                        error_output = result.stderr if result.stderr else result.stdout
                        # å¦‚æœ ffmpeg è½¬æ¢å¤±è´¥ï¼Œç»§ç»­å°è¯•å…¶ä»–æ–¹æ³•
                        print(f"ffmpeg è½¬æ¢å¤±è´¥: {error_output[:200]}")
                
                except subprocess.TimeoutExpired:
                    print("ffmpeg è½¬æ¢è¶…æ—¶ï¼Œå°è¯•å…¶ä»–æ–¹æ³•...")
                except Exception as e:
                    print(f"ffmpeg è½¬æ¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}ï¼Œå°è¯•å…¶ä»–æ–¹æ³•...")
            
            # å¦‚æœ ffmpeg ä¸å¯ç”¨æˆ–è½¬æ¢å¤±è´¥ï¼Œå°è¯•è®© Whisper ç›´æ¥å¤„ç†ï¼ˆWhisper æœ‰å†…ç½® ffmpeg æ”¯æŒï¼‰
            if audio_array is None:
                print("å°è¯•è®© Whisper ç›´æ¥å¤„ç†éŸ³é¢‘æ–‡ä»¶ï¼ˆä½¿ç”¨å†…ç½® ffmpeg æ”¯æŒï¼‰...")
                try:
                    result = _whisper_transcribe(whisper_model, audio_path, language="zh")
                    text = result["text"].strip()
                    if text:
                        return text
                    return "è¯­éŸ³è¯†åˆ«æˆåŠŸï¼Œä½†æœªè¯†åˆ«åˆ°æ–‡æœ¬å†…å®¹ã€‚è¯·æ£€æŸ¥éŸ³é¢‘æ˜¯å¦åŒ…å«è¯­éŸ³ã€‚"
                except Exception as e_whisper:
                    # Whisper ç›´æ¥å¤„ç†ä¹Ÿå¤±è´¥
                    if ffmpeg_available:
                        return f"éŸ³é¢‘å¤„ç†å¤±è´¥ã€‚librosa é”™è¯¯: {error_msg}ã€‚Whisper ç›´æ¥å¤„ç†ä¹Ÿå¤±è´¥: {str(e_whisper)}"
                    else:
                        return f"éŸ³é¢‘å¤„ç†å¤±è´¥ã€‚librosa é”™è¯¯: {error_msg}ã€‚Whisper ç›´æ¥å¤„ç†ä¹Ÿå¤±è´¥: {str(e_whisper)}ã€‚æç¤ºï¼šç³»ç»Ÿ ffmpeg ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿä¾èµ–æˆ–å°è¯•ä½¿ç”¨ WAV æ ¼å¼æ–‡ä»¶ã€‚"
        
        # å¦‚æœæˆåŠŸåŠ è½½äº†éŸ³é¢‘æ•°ç»„ï¼Œä½¿ç”¨å®ƒè¿›è¡Œè½¬å½•
        if audio_array is not None and len(audio_array) > 0:
            # æ ‡å‡†åŒ–éŸ³é¢‘æ•°æ®ï¼ˆç¡®ä¿åœ¨åˆç†èŒƒå›´å†…ï¼‰
            if np.max(np.abs(audio_array)) > 0:
                audio_array = audio_array / np.max(np.abs(audio_array))
            
            # ç­–ç•¥4ï¼šç›´æ¥ä¼ é€’ numpy array ç»™ Whisper
            try:
                result = _whisper_transcribe(whisper_model, audio_array, language="zh")
                text = result["text"].strip()
                if text:
                    return text
                return "è¯­éŸ³è¯†åˆ«æˆåŠŸï¼Œä½†æœªè¯†åˆ«åˆ°æ–‡æœ¬å†…å®¹ã€‚è¯·æ£€æŸ¥éŸ³é¢‘æ˜¯å¦åŒ…å«è¯­éŸ³ã€‚"
            except Exception as e:
                # å¦‚æœç›´æ¥ä¼ é€’æ•°ç»„å¤±è´¥ï¼Œä¿å­˜ä¸ºä¸´æ—¶ WAV æ–‡ä»¶å†å¤„ç†
                try:
                    if temp_wav_path is None:
                        temp_wav = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
                        temp_wav_path = temp_wav.name
                        temp_wav.close()
                    
                    # ä¿å­˜ä¸º WAV æ ¼å¼
                    try:
                        sf.write(temp_wav_path, audio_array, sample_rate)
                    except Exception:
                        # å¦‚æœ soundfile å¤±è´¥ï¼Œä½¿ç”¨ wave æ¨¡å—
                        import wave
                        audio_int16 = (audio_array * 32767).astype(np.int16)
                        with wave.open(temp_wav_path, 'wb') as wf:
                            wf.setnchannels(1)
                            wf.setsampwidth(2)
                            wf.setframerate(sample_rate)
                            wf.writeframes(audio_int16.tobytes())
                    
                    # ä½¿ç”¨æ–‡ä»¶è·¯å¾„è¿›è¡Œè½¬å½•
                    result = _whisper_transcribe(whisper_model, temp_wav_path, language="zh")
                    text = result["text"].strip()
                    if text:
                        return text
                    return "è¯­éŸ³è¯†åˆ«æˆåŠŸï¼Œä½†æœªè¯†åˆ«åˆ°æ–‡æœ¬å†…å®¹ã€‚è¯·æ£€æŸ¥éŸ³é¢‘æ˜¯å¦åŒ…å«è¯­éŸ³ã€‚"
                except Exception as e2:
                    return f"å¤„ç†éŸ³é¢‘æ•°ç»„å¤±è´¥: {str(e)}ã€‚ä¿å­˜ä¸ºæ–‡ä»¶åå¤„ç†ä¹Ÿå¤±è´¥: {str(e2)}"
        
        return "æ— æ³•åŠ è½½éŸ³é¢‘æ–‡ä»¶ã€‚è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼Œæˆ–å°è¯•è½¬æ¢ä¸º WAV æ ¼å¼ã€‚"
        
    except Exception as e:
        return f"è¯­éŸ³è¯†åˆ«è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
    
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_wav_path and os.path.exists(temp_wav_path) and temp_wav_path != audio_path:
            try:
                os.unlink(temp_wav_path)
            except:
                pass


def main():
    """ä¸»å‡½æ•°ã€‚"""
    st.set_page_config(
        page_title="ç²¾é…¿å•¤é…’æ™ºèƒ½åŠ©æ‰‹",
        page_icon="ğŸº",
        layout="wide",
    )
    
    st.title("ğŸº ç²¾é…¿å•¤é…’æ™ºèƒ½åŠ©æ‰‹")
    st.markdown("åŸºäº Qwen2-VL å¤šæ¨¡æ€å¤§æ¨¡å‹çš„ç²¾é…¿å•¤é…’çŸ¥è¯†é—®ç­”ç³»ç»Ÿ")
    
    # æ˜¾å­˜ä¼˜åŒ–æç¤º
    with st.expander("ğŸ’¡ ä½¿ç”¨æç¤º", expanded=False):
        st.markdown("""
        - **å›¾åƒè¯†åˆ«**ï¼šç³»ç»Ÿä¼šè‡ªåŠ¨è°ƒæ•´å›¾åƒå¤§å°ï¼ˆæœ€å¤§512åƒç´ ï¼‰ä»¥ä¼˜åŒ–æ˜¾å­˜ä½¿ç”¨
        - **æ˜¾å­˜ä¸è¶³**ï¼šå¦‚é‡åˆ°æ˜¾å­˜é”™è¯¯ï¼Œè¯·å°è¯•ä¸Šä¼ æ›´å°çš„å›¾ç‰‡æˆ–æ¸…ç©ºå¯¹è¯å†å²
        - **å“åº”æ—¶é—´**ï¼šå›¾åƒåˆ†æå¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…
        - **è¯­éŸ³è¯†åˆ«**ï¼šæ¨èä½¿ç”¨ WAV æ ¼å¼éŸ³é¢‘æ–‡ä»¶ï¼Œå…¶ä»–æ ¼å¼ï¼ˆMP3ã€M4Aï¼‰å¯èƒ½éœ€è¦åœ¨ç³»ç»Ÿå®‰è£… ffmpeg
        """)
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("åŠŸèƒ½é€‰æ‹©")
        mode = st.radio(
            "é€‰æ‹©æ¨¡å¼",
            ["ğŸ“ æ–‡æœ¬å¯¹è¯", "ğŸ–¼ï¸ å›¾åƒè¯†åˆ«", "ğŸ¤ è¯­éŸ³è¾“å…¥"],
        )
    
    # åˆå§‹åŒ–å¯¹è¯å†å²
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    
    # æ–‡æœ¬å¯¹è¯æ¨¡å¼
    if mode == "ğŸ“ æ–‡æœ¬å¯¹è¯":
        st.header("æ–‡æœ¬å¯¹è¯")
        
        # æ˜¾ç¤ºå¯¹è¯å†å²
        for i, (role, content) in enumerate(st.session_state.chat_history):
            if role == "user":
                st.write(f"**ä½ ï¼š** {content}")
            else:
                st.write(f"**åŠ©æ‰‹ï¼š** {content}")
            st.divider()
        
        # è¾“å…¥æ¡†
        user_input = st.text_input("è¾“å…¥é—®é¢˜", placeholder="ä¾‹å¦‚ï¼šä»€ä¹ˆæ˜¯æµ‘æµŠIPAï¼Ÿå¦‚ä½•åˆ¤æ–­å‘é…µæ˜¯å¦å®Œæˆï¼Ÿ")
        
        col1, col2 = st.columns([1, 10])
        with col1:
            submit = st.button("å‘é€", type="primary")
        with col2:
            clear = st.button("æ¸…ç©ºå†å²")
        
        if clear:
            st.session_state.chat_history = []
            st.rerun()
        
        if submit and user_input:
            with st.spinner("æ­£åœ¨æ€è€ƒ..."):
                try:
                    # æ¸…ç©ºæ˜¾å­˜ç¼“å­˜
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                    
                    # ä¼ é€’å¯¹è¯å†å²ç»™æ¨¡å‹
                    response = generate_reply(
                        user_input,
                        max_new_tokens=256,
                        chat_history=st.session_state.chat_history
                    )
                    st.session_state.chat_history.append(("user", user_input))
                    st.session_state.chat_history.append(("assistant", response))
                    
                    # æ¸…ç©ºæ˜¾å­˜ç¼“å­˜
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                    
                    st.rerun()
                except torch.cuda.OutOfMemoryError as e:
                    st.error(f"æ˜¾å­˜ä¸è¶³ï¼š{str(e)}")
                    st.info("æç¤ºï¼šè¯·æ¸…ç©ºå¯¹è¯å†å²æˆ–é‡å¯ç•Œé¢é‡Šæ”¾æ˜¾å­˜")
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                except Exception as e:
                    st.error(f"å¤„ç†å¤±è´¥ï¼š{str(e)}")
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
    
    # å›¾åƒè¯†åˆ«æ¨¡å¼
    elif mode == "ğŸ–¼ï¸ å›¾åƒè¯†åˆ«":
        st.header("å›¾åƒè¯†åˆ«")
        
        uploaded_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡", type=["png", "jpg", "jpeg"])
        question = st.text_input("é—®é¢˜ï¼ˆå¯é€‰ï¼‰", placeholder="ä¾‹å¦‚ï¼šè¯·åˆ†æè¿™å¼ å›¾ç‰‡ï¼Œåˆ¤æ–­é…µæ¯æ´»æ€§æ˜¯å¦æ­£å¸¸ï¼Ÿ")
        
        if uploaded_file is not None:
            image = Image.open(uploaded_file).convert("RGB")
            
            # æå‰è°ƒæ•´å›¾åƒå¤§å°ä»¥èŠ‚çœæ˜¾å­˜ï¼ˆé™åˆ¶ä¸º512åƒç´ ï¼‰
            original_size = image.size
            image = resize_image(image, max_size=512)
            resized_size = image.size
            
            if original_size != resized_size:
                st.info(f"å›¾åƒå·²ä» {original_size} è°ƒæ•´ä¸º {resized_size} ä»¥ä¼˜åŒ–æ˜¾å­˜ä½¿ç”¨")
            
            st.image(image, caption="ä¸Šä¼ çš„å›¾ç‰‡ï¼ˆå·²ä¼˜åŒ–ï¼‰", use_container_width=True)
            
            if st.button("åˆ†æå›¾ç‰‡", type="primary"):
                if not question:
                    question = "è¯·åˆ†æè¿™å¼ å›¾ç‰‡å¹¶å›ç­”ç›¸å…³é—®é¢˜ã€‚"
                
                with st.spinner("æ­£åœ¨åˆ†æå›¾ç‰‡ï¼ˆå¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼‰..."):
                    try:
                        # æ¸…ç©ºæ˜¾å­˜ç¼“å­˜
                        if torch.cuda.is_available():
                            torch.cuda.empty_cache()
                        
                        response = generate_reply(question, image=image, max_new_tokens=128)
                        st.write(f"**é—®é¢˜ï¼š** {question}")
                        st.write(f"**å›ç­”ï¼š** {response}")
                        
                        # å†æ¬¡æ¸…ç©ºæ˜¾å­˜ç¼“å­˜
                        if torch.cuda.is_available():
                            torch.cuda.empty_cache()
                    except torch.cuda.OutOfMemoryError as e:
                        st.error(f"æ˜¾å­˜ä¸è¶³ï¼š{str(e)}")
                        st.info("æç¤ºï¼šè¯·å°è¯•ä¸Šä¼ æ›´å°çš„å›¾ç‰‡ï¼Œæˆ–é‡å¯ç•Œé¢é‡Šæ”¾æ˜¾å­˜")
                        if torch.cuda.is_available():
                            torch.cuda.empty_cache()
                    except Exception as e:
                        st.error(f"å¤„ç†å¤±è´¥ï¼š{str(e)}")
                        if torch.cuda.is_available():
                            torch.cuda.empty_cache()
    
    # è¯­éŸ³è¾“å…¥æ¨¡å¼
    elif mode == "ğŸ¤ è¯­éŸ³è¾“å…¥":
        st.header("è¯­éŸ³è¾“å…¥")
        
        # åˆå§‹åŒ–è¯­éŸ³å¯¹è¯å†å²
        if "voice_chat_history" not in st.session_state:
            st.session_state.voice_chat_history = []
        
        # æ˜¾ç¤ºå¯¹è¯å†å²
        if st.session_state.voice_chat_history:
            st.subheader("å¯¹è¯å†å²")
            for i, (role, content) in enumerate(st.session_state.voice_chat_history):
                if role == "user":
                    st.write(f"**ä½ ï¼ˆè¯­éŸ³ï¼‰ï¼š** {content}")
                else:
                    st.write(f"**åŠ©æ‰‹ï¼š** {content}")
                st.divider()
        
        if not SPEECH_AVAILABLE:
            st.warning("âš ï¸ è¯­éŸ³è¯†åˆ«åŠŸèƒ½æœªå®‰è£…ï¼Œè¯·å®‰è£…ï¼š`pip install openai-whisper soundfile`")
        else:
            st.info("ğŸ’¡ **æç¤º**ï¼šæ¨èä½¿ç”¨ WAV æ ¼å¼éŸ³é¢‘æ–‡ä»¶ä»¥è·å¾—æœ€ä½³å…¼å®¹æ€§ã€‚æ”¯æŒæ ¼å¼ï¼šWAVï¼ˆæ¨èï¼‰ã€MP3ã€M4A")
            uploaded_audio = st.file_uploader("ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶", type=["wav", "mp3", "m4a"])
            
            # æ¸…ç©ºå†å²æŒ‰é’®
            if st.button("æ¸…ç©ºå¯¹è¯å†å²", key="voice_clear"):
                st.session_state.voice_chat_history = []
                st.rerun()
            
            if uploaded_audio is not None:
                # ä¿å­˜ä¸´æ—¶æ–‡ä»¶ï¼ˆä¿ç•™åŸå§‹æ‰©å±•åï¼‰
                file_ext = Path(uploaded_audio.name).suffix or ".wav"
                with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as tmp_file:
                    tmp_file.write(uploaded_audio.read())
                    tmp_path = tmp_file.name
                
                st.audio(uploaded_audio)
                
                # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
                file_size = os.path.getsize(tmp_path) / (1024 * 1024)  # MB
                st.caption(f"æ–‡ä»¶å¤§å°: {file_size:.2f} MB | æ ¼å¼: {file_ext}")
                
                if st.button("è¯†åˆ«å¹¶å›ç­”", type="primary"):
                    with st.spinner("æ­£åœ¨è¯†åˆ«è¯­éŸ³ï¼ˆå¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼‰..."):
                        try:
                            text = transcribe_audio(tmp_path)
                            if text and not text.startswith("è¯­éŸ³è¯†åˆ«å¤±è´¥") and not text.startswith("è¯­éŸ³è¯†åˆ«åŠŸèƒ½æœªå®‰è£…"):
                                st.success("âœ… è¯†åˆ«æˆåŠŸï¼")
                                st.write(f"**è¯†åˆ«åˆ°çš„æ–‡æœ¬ï¼š** {text}")
                                with st.spinner("æ­£åœ¨ç”Ÿæˆå›ç­”..."):
                                    try:
                                        # ä¼ é€’å¯¹è¯å†å²ç»™æ¨¡å‹ï¼Œå¢åŠ  token é™åˆ¶ä»¥è·å¾—æ›´å®Œæ•´çš„å›ç­”
                                        response = generate_reply(
                                            text,
                                            max_new_tokens=256,  # å¢åŠ åˆ° 256ï¼Œä¸æ–‡æœ¬å¯¹è¯ä¸€è‡´
                                            chat_history=st.session_state.voice_chat_history
                                        )
                                        
                                        # ä¿å­˜åˆ°å¯¹è¯å†å²
                                        st.session_state.voice_chat_history.append(("user", text))
                                        st.session_state.voice_chat_history.append(("assistant", response))
                                        
                                        st.success("âœ… å›ç­”å·²ç”Ÿæˆï¼")
                                        st.rerun()  # åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºæ›´æ–°çš„å¯¹è¯å†å²
                                    except Exception as e:
                                        st.error(f"ç”Ÿæˆå›ç­”å¤±è´¥: {str(e)}")
                            else:
                                st.error("âŒ " + text)
                                if "ffmpeg" in text.lower():
                                    st.info("ğŸ’¡ **è§£å†³æ–¹æ¡ˆï¼š**\n"
                                            "1. å®‰è£… ffmpegï¼š`sudo apt-get install ffmpeg`\n"
                                            "2. æˆ–è€…ä¸Šä¼  WAV æ ¼å¼çš„éŸ³é¢‘æ–‡ä»¶ï¼ˆä¸éœ€è¦ ffmpegï¼‰")
                        except Exception as e:
                            st.error(f"å¤„ç†å¤±è´¥: {str(e)}")
                        finally:
                            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                            try:
                                os.unlink(tmp_path)
                            except:
                                pass
    
    # åº•éƒ¨ä¿¡æ¯
    st.divider()
    st.markdown("**æç¤ºï¼š** æ¨¡å‹å·²åŠ è½½ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨å„é¡¹åŠŸèƒ½ã€‚")


if __name__ == "__main__":
    main()

